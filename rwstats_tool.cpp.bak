#include "drmemtrace/analysis_tool.h"
#include "drmemtrace/memref.h"

#include <inttypes.h>
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <unordered_map>
#include <unordered_set>
#include <vector>
#include <algorithm>
#include <limits>
#include <string>

using namespace dynamorio::drmemtrace;

// ---------- tiny helpers ----------
static inline double log2_safe(double x) { return x > 0.0 ? log2(x) : 0.0; }
static inline bool is_nan(double x) { return std::isnan(x) != 0; }
static inline uint64_t abs_diff_u64(uint64_t a, uint64_t b) { return (a > b) ? (a - b) : (b - a); }

static void fmt_double(char *buf, size_t n, double v, const char *fmt = "%.6f") {
    if (is_nan(v)) snprintf(buf, n, "nan");
    else snprintf(buf, n, fmt, v);
}

static double entropy_from_counts(const std::unordered_map<uint64_t,uint64_t> &m, uint64_t total) {
    if (total == 0 || m.empty()) return std::numeric_limits<double>::quiet_NaN();
    double H = 0.0;
    for (auto &kv : m) {
        double p = (double)kv.second / (double)total;
        H -= p * log2_safe(p);
    }
    return H;
}

static uint64_t footprint90_from_counts(const std::unordered_map<uint64_t,uint64_t> &m, uint64_t total) {
    if (total == 0 || m.empty()) return 0;
    std::vector<uint64_t> freq; freq.reserve(m.size());
    for (auto &kv : m) freq.push_back(kv.second);
    std::sort(freq.begin(), freq.end(), std::greater<uint64_t>());
    uint64_t need = (uint64_t)ceil(0.9 * (double)total);
    uint64_t acc = 0;
    size_t k = 0;
    for (; k < freq.size(); ++k) { acc += freq[k]; if (acc >= need) break; }
    return (uint64_t)(k + 1);
}

static double avg_from_hist(const std::unordered_map<uint64_t,uint64_t> &hist) {
    if (hist.empty()) return std::numeric_limits<double>::quiet_NaN();
    long double num = 0.0, den = 0.0;
    for (auto &kv : hist) { num += (long double)kv.first * (long double)kv.second; den += (long double)kv.second; }
    if (den == 0.0) return std::numeric_limits<double>::quiet_NaN();
    return (double)(num / den);
}

static double entropy_of_hist(const std::unordered_map<uint64_t,uint64_t> &hist) {
    uint64_t tot = 0; for (auto &kv : hist) tot += kv.second;
    if (tot == 0) return std::numeric_limits<double>::quiet_NaN();
    double H = 0.0;
    for (auto &kv : hist) { double p = (double)kv.second / (double)tot; H -= p * log2_safe(p); }
    return H;
}

static uint64_t pctile_from_hist(const std::unordered_map<uint64_t,uint64_t> &hist, uint64_t total, double q) {
    if (total == 0 || hist.empty()) return 0;
    std::vector<uint64_t> keys; keys.reserve(hist.size());
    for (auto &kv : hist) keys.push_back(kv.first);
    std::sort(keys.begin(), keys.end()); // ascending
    uint64_t need = (uint64_t)ceil(q * (double)total);
    uint64_t acc = 0;
    for (uint64_t k : keys) {
        acc += hist.at(k);
        if (acc >= need) return k;
    }
    return keys.back();
}

// ========== Analysis tool ==========
class rwstats_tool_t : public analysis_tool_t {
public:
    rwstats_tool_t() {
        const char *s;
        if ((s = getenv("RWSTATS_INTERVAL")) != nullptr) interval_ = strtoull(s, nullptr, 10);
        if ((s = getenv("RWSTATS_STRIDE_CAP_BYTES")) != nullptr) stride_cap_B_ = strtoull(s, nullptr, 10);
        if ((s = getenv("RWSTATS_F90_INTERVAL")) != nullptr) f90_interval_ = (atoi(s) != 0);
        if ((s = getenv("RWSTATS_LOCAL_BITS")) != nullptr) local_bits_ = std::max(0, atoi(s));
        if ((s = getenv("RWSTATS_ADDR_SHIFT")) != nullptr) addr_shift_ = std::max(0, atoi(s));
    }

    bool process_memref(const memref_t &m) override {
        const trace_type_t t = m.data.type;
        if (t != TRACE_TYPE_READ && t != TRACE_TYPE_WRITE) return true;

        const uint64_t addr = (uint64_t)m.data.addr;
        const uint64_t size = (uint64_t)m.data.size;

        // canonical “units”
        const uint64_t addr_key  = addr >> addr_shift_;  // for per-type frequency/granularity if desired
        const uint64_t line_tag  = addr >> 6;            // 64B lines
        const uint64_t page_tag  = addr >> 12;           // 4KB pages
        const uint64_t local_tag = addr_key & ~((local_bits_ > 0 ? ((1ULL<<local_bits_) - 1) : 0ULL));

        total_refs_++;
        if (t == TRACE_TYPE_READ) { reads_++;  bytes_read_  += size;  }
        else                      { writes_++; bytes_written_ += size; }

        // per-type maps (interval + final)
        if (t == TRACE_TYPE_READ) {
            read_freq_i_[addr_key]++;  read_freq_f_[addr_key]++;
            read_local_i_[local_tag]++; read_local_f_[local_tag]++;
        } else {
            write_freq_i_[addr_key]++; write_freq_f_[addr_key]++;
            write_local_i_[local_tag]++; write_local_f_[local_tag]++;
        }

        // interval unique footprint (line/page)
        uniq_lines_i_.insert(line_tag);
        uniq_pages_i_.insert(page_tag);

        // final unique footprint too
        uniq_lines_f_.insert(line_tag);
        uniq_pages_f_.insert(page_tag);

        // stride stats (bytes & “lines”)
        if (have_prev_) {
            const uint64_t prev_line = prev_line_tag_;
            const uint64_t line_stride = abs_diff_u64(line_tag, prev_line);
            const uint64_t byte_stride = abs_diff_u64(addr, prev_addr_);
            // cap & over-cap counts
            const uint64_t capL = stride_cap_B_ >> 6; // convert bytes cap to “lines”
            const uint64_t b_c = (byte_stride > stride_cap_B_) ? (stride_bytes_over_cap_i_++, stride_bytes_over_cap_f_++, stride_cap_B_) : byte_stride;
            const uint64_t l_c = (line_stride > capL)          ? (line_stride_over_cap_i_++,  line_stride_over_cap_f_++,  capL)          : line_stride;

            // interval & final hist
            strideB_hist_i_[b_c]++; strideB_hist_f_[b_c]++;
            strideL_hist_i_[l_c]++; strideL_hist_f_[l_c]++;

            // interval sums
            sum_strideB_i_ += (double)byte_stride;
            sum_strideL_i_ += (double)line_stride;
            stride_pairs_i_++;
            if (byte_stride <= 64) stride_le_64_i_++;
        } else {
            have_prev_ = true;
        }
        prev_addr_ = addr;
        prev_line_tag_ = line_tag;

        // periodic snapshot
        if (interval_ > 0 && (total_refs_ % interval_ == 0))
            print_snapshot(/*is_final=*/false);

        return true;
    }

    bool print_results() override {
        print_snapshot(/*is_final=*/true);
        return true;
    }

private:
    // knobs
    uint64_t interval_      = 5000000ULL;   // memrefs per interval; 0 => only final
    uint64_t stride_cap_B_  = (1ULL<<20);   // 1MiB cap for strideB hist
    bool     f90_interval_  = true;         // compute footprint90 on intervals too
    int      local_bits_    = 10;           // for “local” entropy masking
    int      addr_shift_    = 0;            // 0=bytes (recommended for *_freq)

    // totals
    uint64_t total_refs_    = 0;
    uint64_t reads_         = 0, writes_ = 0;
    uint64_t bytes_read_    = 0, bytes_written_ = 0;

    // unique footrpint (interval + final)
    std::unordered_set<uint64_t> uniq_lines_i_, uniq_pages_i_;
    std::unordered_set<uint64_t> uniq_lines_f_, uniq_pages_f_;

    // per-type frequencies (interval + final)
    std::unordered_map<uint64_t,uint64_t> read_freq_i_,  write_freq_i_;
    std::unordered_map<uint64_t,uint64_t> read_freq_f_,  write_freq_f_;
    std::unordered_map<uint64_t,uint64_t> read_local_i_, write_local_i_;
    std::unordered_map<uint64_t,uint64_t> read_local_f_, write_local_f_;

    // stride
    bool     have_prev_ = false;
    uint64_t prev_addr_ = 0;
    uint64_t prev_line_tag_ = 0;

    std::unordered_map<uint64_t,uint64_t> strideB_hist_i_, strideB_hist_f_;
    std::unordered_map<uint64_t,uint64_t> strideL_hist_i_, strideL_hist_f_;
    double   sum_strideB_i_ = 0.0, sum_strideL_i_ = 0.0;
    uint64_t stride_pairs_i_ = 0, stride_le_64_i_ = 0;
    uint64_t stride_bytes_over_cap_i_ = 0, stride_bytes_over_cap_f_ = 0;
    uint64_t line_stride_over_cap_i_  = 0, line_stride_over_cap_f_  = 0;

private:
    void reset_interval() {
        uniq_lines_i_.clear();
        uniq_pages_i_.clear();
        read_freq_i_.clear();
        write_freq_i_.clear();
        read_local_i_.clear();
        write_local_i_.clear();
        strideB_hist_i_.clear();
        strideL_hist_i_.clear();
        sum_strideB_i_ = sum_strideL_i_ = 0.0;
        stride_pairs_i_ = 0; stride_le_64_i_ = 0;
        stride_bytes_over_cap_i_ = 0; line_stride_over_cap_i_ = 0;
    }

    void print_snapshot(bool is_final) {
        // choose interval vs final views
        const auto &rf = is_final ? read_freq_f_  : read_freq_i_;
        const auto &wf = is_final ? write_freq_f_ : write_freq_i_;
        const auto &rl = is_final ? read_local_f_ : read_local_i_;
        const auto &wl = is_final ? write_local_f_: write_local_i_;
        const auto &hB = is_final ? strideB_hist_f_ : strideB_hist_i_;
        const auto &hL = is_final ? strideL_hist_f_ : strideL_hist_i_;

        uint64_t read_total  = 0, write_total = 0;
        for (auto &kv : rf) read_total  += kv.second;
        for (auto &kv : wf) write_total += kv.second;

        const uint64_t read_unique  = (uint64_t)rf.size();
        const uint64_t write_unique = (uint64_t)wf.size();

        const double read_entropy       = entropy_from_counts(rf, read_total);
        const double write_entropy      = entropy_from_counts(wf, write_total);
        const double read_local_entropy = entropy_from_counts(rl, read_total);
        const double write_local_entropy= entropy_from_counts(wl, write_total);

        const uint64_t read_f90  = (is_final || f90_interval_)  ? footprint90_from_counts(rf, read_total)  : 0;
        const uint64_t write_f90 = (is_final || f90_interval_)  ? footprint90_from_counts(wf, write_total) : 0;

        // footprint (unique lines/pages) over current scope
        uint64_t uniq_lines = is_final ? (uint64_t)uniq_lines_f_.size() : (uint64_t)uniq_lines_i_.size();
        uint64_t uniq_pages = is_final ? (uint64_t)uniq_pages_f_.size() : (uint64_t)uniq_pages_i_.size();
        uint64_t footprint_bytes = uniq_lines * 64ULL; // 64B lines

        // H_line/H_page: entropy of line/page distribution in scope (approx from sets => NaN).
        // For a better approximation, count per-line/page frequencies; here we keep NaN to avoid heavy maps.
        double H_line = std::numeric_limits<double>::quiet_NaN();
        double H_page = std::numeric_limits<double>::quiet_NaN();

        // H_stride from strideB histogram
        const double H_stride = entropy_of_hist(hB);

        // stride summaries
        uint64_t stride_pairs = 0; for (auto &kv : hB) stride_pairs += kv.second;
        double avg_strideB = std::numeric_limits<double>::quiet_NaN();
        double avg_strideL = std::numeric_limits<double>::quiet_NaN();
        if (stride_pairs > 0) {
            if (is_final) { avg_strideB = avg_from_hist(hB); avg_strideL = avg_from_hist(hL); }
            else { avg_strideB = sum_strideB_i_ / (double)stride_pairs; avg_strideL = sum_strideL_i_ / (double)stride_pairs; }
        }
        const double p_le_64 = (stride_pairs > 0) ? ((double)stride_le_64_i_ / (double)stride_pairs) : std::numeric_limits<double>::quiet_NaN();

        const uint64_t p50B = pctile_from_hist(hB, stride_pairs, 0.50);
        const uint64_t p90B = pctile_from_hist(hB, stride_pairs, 0.90);
        const uint64_t p99B = pctile_from_hist(hB, stride_pairs, 0.99);
        const uint64_t p50L = pctile_from_hist(hL, stride_pairs, 0.50);
        const uint64_t p90L = pctile_from_hist(hL, stride_pairs, 0.90);
        const uint64_t p99L = pctile_from_hist(hL, stride_pairs, 0.99);

        // reuse rate: simple 1 - uniq_lines / total_refs_in_scope
        double reuse_rate = std::numeric_limits<double>::quiet_NaN();
        uint64_t scope_total = read_total + write_total;
        if (scope_total > 0) reuse_rate = 1.0 - ((double)uniq_lines / (double)scope_total);

        // stride over-cap (interval/final)
        const uint64_t over_b = is_final ? stride_bytes_over_cap_f_ : stride_bytes_over_cap_i_;
        const uint64_t over_l = is_final ? line_stride_over_cap_f_  : line_stride_over_cap_i_;

        // format doubles
        char bHline[32], bHpage[32], bHstride[32], bReuse[32], bAvgB[32], bAvgL[32], bP64[32];
        fmt_double(bHline, sizeof(bHline), H_line);
        fmt_double(bHpage, sizeof(bHpage), H_page);
        fmt_double(bHstride, sizeof(bHstride), H_stride);
        fmt_double(bReuse, sizeof(bReuse), reuse_rate);
        fmt_double(bAvgB, sizeof(bAvgB), avg_strideB);
        fmt_double(bAvgL, sizeof(bAvgL), avg_strideL);
        fmt_double(bP64,  sizeof(bP64),  p_le_64);

        fprintf(stderr,
            "scope=%s"
            ",reads=%" PRIu64 ",writes=%" PRIu64
            ",bytes_read=%" PRIu64 ",bytes_written=%" PRIu64
            ",uniq_lines=%" PRIu64 ",uniq_pages=%" PRIu64 ",footprint_bytes=%" PRIu64
            ",H_line=%s,H_page=%s,H_stride=%s"
            ",reuse_rate=%s,avg_stride=%s,avg_line_stride=%s,p_stride_le_64=%s"
            ",p50_strideB=%" PRIu64 ",p90_strideB=%" PRIu64 ",p99_strideB=%" PRIu64
            ",p50_strideL=%" PRIu64 ",p90_strideL=%" PRIu64 ",p99_strideL=%" PRIu64
            ",stride_bytes_over_cap=%" PRIu64 ",line_stride_over_cap=%" PRIu64
            ",read_total=%" PRIu64 ",read_unique=%" PRIu64 ",read_entropy=%.6f,read_local_entropy=%.6f,read_footprint90=%" PRIu64
            ",write_total=%" PRIu64 ",write_unique=%" PRIu64 ",write_entropy=%.6f,write_local_entropy=%.6f,write_footprint90=%" PRIu64
            "\n",
            (is_final ? "final" : "interval"),
            reads_, writes_,
            bytes_read_, bytes_written_,
            uniq_lines, uniq_pages, footprint_bytes,
            bHline, bHpage, bHstride,
            bReuse, bAvgB, bAvgL, bP64,
            p50B, p90B, p99B, p50L, p90L, p99L,
            over_b, over_l,
            read_total, read_unique, read_entropy, read_local_entropy, read_f90,
            write_total, write_unique, write_entropy, write_local_entropy, write_f90
        );

        if (!is_final) reset_interval();
    }
};

// factory
analysis_tool_t *rwstats_tool_create() { return new rwstats_tool_t(); }

